source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
P_1 - andStart
andStart - P_1
andStartNtp - P_0
source('~/.active-rstudio-document', echo=TRUE)
andStartNtp - P_0
(andStartNtp - P_0)/1000/60
(andStartNtp - P_0)/1000/60/60
(andStartNtp - P_0)/1000/60/60/30
source('~/.active-rstudio-document', echo=TRUE)
(andStartNtp - P_0)/1000/60/60/30
(P_0 - andStartNtp)/1000/60/60/30
source('~/.active-rstudio-document', echo=TRUE)
P_0-delta
P_0+delta
P_0 + delta
P_0 + delta-P_1
P_1 - delta
andStart-delta
delta/1000/60/60
delta/1000/60/60/30
delta/1000/60/60/30/12
delta/1000/60/60/24/30/12
delta/1000/60/60/24/30
delta/1000/60/60/24/30/12
P_1 + andStart
P_0 + andStart
delta > 2,147,483,647
delta > 2147483647
1458544089720+377280
1458544089720-1458543712440
(1458544089720-1458543712440)/1000/60/60
(1458544089720-1458543712440)/1000/60
source('~/Documents/R programing/Testing.R')
andStart-delta
andEnd-delta
1458544089720-1458544089720
1458543712440-1458544089720
source('~/Documents/R programing/Testing2.R', echo=TRUE)
as.POSIXlt(delta, origin="1970-01-01", tz="Slovenia/Ljubljana")
?as.POSIXlt
as.POSIXlt(delta, origin="1970-01-01", tz="GMT+1")
as.POSIXlt(delta, origin="1970-01-01", tz="GMT")
Sys.timezone(location = TRUE)
as.POSIXlt(delta, origin="1970-01-01", tz="Europe/Ljubljana")
source('~/Documents/R programing/Testing2.R', echo=TRUE)
toDate(andStart)
toDate(andStart/1000)
toDate(andStartNtp)
source('~/Documents/R programing/Testing2.R', echo=TRUE)
toDate(andStart)
toDate(andStartNtp)
toDate(andStart+delta)
toDate(andStart-delta)
toDate(andEnd-delta)
toDate(1458628139101)
toDate(4260380)
toDate(660419)
if (!requireNamespace("devtools", quietly = TRUE))
install.packages("devtools")
devtools::install_github("calligross/ggthemeassist")
library(ggplot2)
nmmaps<-read.csv("chicago-nmmaps.csv", as.is=T)
nmmaps$date<-as.Date(nmmaps$date)
nmmaps<-nmmaps[nmmaps$date>as.Date("1996-12-31"),]
nmmaps$year<-substring(nmmaps$date,1,4)
head(nmmaps)
# ggplot2 examples
library(ggplot2)
# create factors with value labels
mtcars$gear <- factor(mtcars$gear,levels=c(3,4,5),
labels=c("3gears","4gears","5gears"))
mtcars$am <- factor(mtcars$am,levels=c(0,1),
labels=c("Automatic","Manual"))
mtcars$cyl <- factor(mtcars$cyl,levels=c(4,6,8),
labels=c("4cyl","6cyl","8cyl"))
# Kernel density plots for mpg
# grouped by number of gears (indicated by color)
qplot(mpg, data=mtcars, geom="density", fill=gear, alpha=I(.5),
main="Distribution of Gas Milage", xlab="Miles Per Gallon",
ylab="Density")
ylab="Density")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
ggThemeAssist:::ggThemeAssistAddin()
source('~/.active-rstudio-document', echo=TRUE)
ggThemeAssist:::ggThemeAssistAddin()
getwd()
setwd("Practical Machine Learning/Course Project/")
load("project.RData")
pred <- predict(fit_ensemble, newdata=pred_test)
prob <- predict(fit_ensemble, newdata=pred_test, type="prob")
prob$pred <- pred
prob$classe <- pred_test$classe
filter(prob, pred!=classe)
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(doMC))
pred <- predict(fit_ensemble, newdata=pred_test)
prob <- predict(fit_ensemble, newdata=pred_test, type="prob")
prob$pred <- pred
prob$classe <- pred_test$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", A, 1-A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(pred=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
pred <- predict(fit_ensemble, newdata=pred_test)
prob <- predict(fit_ensemble, newdata=pred_test, type="prob")
prob$pred <- pred
prob$classe <- pred_test$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", A, 1-A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
pre <- prediction(prob_A$prob, pred_test$binClasse)
library(ggplot2)
library(ROCR)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
pre <- prediction(prob_A$prob, pred_test$binClasse)
prob_A$prob
head(prob_A$prob)
head(pred_test$binClasse)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", 1-A, A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
head(prob_A$prob)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
model1 <- train(classe~., training, method="rpart")
pred_validation1 <- predict(model1, newdata = validation)
pred_submission1 <- predict(model1, newdata = testing)
print(RMSE(as.numeric(pred_validation1), as.numeric(validation$classe)))
print(confusionMatrix(validation$classe, pred_validation1)$overall[1])
pred <- predict(model1, newdata=pred_validation1)
prob <- predict(model1, newdata=pred_validation1, type="prob")
prob$pred <- pred
prob$classe <- pred_test$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", 1-A, A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
head(prob_A$prob)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
pred <- predict(model1, newdata=pred_validation1)
prob <- predict(model1, newdata=pred_validation1, type="prob")
prob$pred <- pred
prob$classe <- validation$classe
filter(prob, pred!=classe)
pred <- predict(model1, newdata=pred_validation1)
pred <- predict(model1, newdata=pred_validation1)
model1 <- train(classe~., training, method="rpart")
pred_validation1 <- predict(model1, newdata = validation)
pred_submission1 <- predict(model1, newdata = testing)
print(confusionMatrix(validation$classe, pred_validation1)$overall[1])
View(validation)
load("~/Documents/R programing/Practical Machine Learning/Course Project/project.RData")
View(validation)
View(testing)
View(training_data)
if(!file.exists("./pml-training.csv")){
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileUrl, destfile="./pml-training.csv", method="curl")
}
if(!file.exists("./pml-testing.csv")){
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrl, destfile="./pml-testing.csv", method="curl")
}
training_data <- read.csv("./pml-training.csv", na.strings = c("#DIV/0!", "", "NA"))
submission_data <- read.csv("./pml-testing.csv", na.strings = c("#DIV/0!", "", "NA"))
# Remove the new_window because it's sparse and some features have values only on that observation
training_data <- training_data %>% filter(new_window == "no")
# This feature has no variablility so we will remove it
training_data$new_window <- NULL
submission_data$new_window <- NULL
# Removing columns with all values NA
training_data <- training_data[colSums(!is.na(training_data)) > 0]
submission_data <- submission_data[colSums(!is.na(submission_data)) > 0]
# Probably should remove timestamps, as were not going to model the data as poisson or time-series
training_data$X <- NULL
submission_data$X <- NULL
training_data$cvtd_timestamp <- NULL
submission_data$cvtd_timestamp <- NULL
training_data$raw_timestamp_part_1 <- NULL
submission_data$raw_timestamp_part_1 <- NULL
training_data$raw_timestamp_part_2 <- NULL
submission_data$raw_timestamp_part_2 <- NULL
# Check to see which columns in the testing dataset are NOT present in the training_data dataset
test_extras <- colnames(submission_data)[which(colnames(submission_data) %in% colnames(training_data)==FALSE)]
submission_data <- submission_data[ , !(names(submission_data) %in% test_extras)]
train_extras <- colnames(training_data)[which(colnames(training_data) %in% colnames(submission_data)==FALSE)]
training_data <- training_data[ , !(names(training_data) %in% train_extras[-which(train_extras=="classe")])]
View(training_data)
set.seed(33833)
inTrain = createDataPartition(training_data$classe, p = 0.7, list = FALSE)
training <- training_data[inTrain,]
validation_data <- training_data[-inTrain,]
inValidation = createDataPartition(validation_data$classe, p = 0.5, list = FALSE)
validation <- validation_data[inValidation,]
testing <- validation_data[-inValidation,]
model1 <- train(classe~., training, method="rpart")
pred_validation1 <- predict(model1, newdata = validation)
pred_submission1 <- predict(model1, newdata = testing)
print(confusionMatrix(validation$classe, pred_validation1)$overall[1])
pred <- predict(model1, newdata=pred_validation1)
prob <- predict(model1, newdata=pred_validation1, type="prob")
prob$pred <- pred
prob$classe <- validation$classe
filter(prob, pred!=classe)
pred <- predict(model1, newdata=pred_validation1)
pred <- predict(model1, newdata=validation)
prob <- predict(model1, newdata=validation, type="prob")
prob$pred <- pred
prob$classe <- validation$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", 1-A, A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
head(prob_A$prob)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
model1 <- train(classe~., binarizedTrain, method="rpart")
pred_validation1 <- predict(model1, newdata = binarizedValidate)
binarizedTrain <- training %>% mutate(classe=ifelse(classe=="A", 1, 0))
binarizedValidate <- validation %>% mutate(classe=ifelse(classe=="A", 1, 0))
model1 <- train(classe~., binarizedTrain, method="rpart")
pred_validation1 <- predict(model1, newdata = binarizedValidate)
pred <- predict(model1, newdata=binarizedValidate)
prob <- predict(model1, newdata=binarizedValidate, type="prob")
pred <- predict(model1, newdata=binarizedValidate)
prob <- predict(model1, newdata=binarizedValidate, type="prob")
lirary(pROC)
library(pROC)
plot.roc(roc(pred_validation1, binarizedValidate$classe))
pred <- predict(model1, newdata=binarizedValidate)
prob <- predict(model1, newdata=binarizedValidate, type="prob")
prob$pred <- pred
prob$classe <- validation$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", 1-A, A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
head(prob_A$prob)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
pred <- predict(model1, newdata=binarizedValidate)
prob <- predict(model1, newdata=binarizedValidate, type="prob")
prob <- predict(model1, newdata=binarizedValidate)
pred <- predict(model1, newdata=binarizedValidate)
pre <- prediction(pred, binarizedValidate$binClasse)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
pred <- predict(model1, newdata=binarizedValidate)
prob <- predict(model1, newdata=binarizedValidate, type="prob")
prob$pred <- pred
prob$classe <- validation$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", A, A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
head(prob_A$prob)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
pred <- predict(fit_ensemble, newdata=pred_test$classe)
load("~/Documents/R programing/Practical Machine Learning/Course Project/project.RData")
pred <- predict(fit_ensemble, newdata=pred_test$classe)
pred <- predict(fit_ensemble, newdata=pred_test$classe)
binarizedTrain <- training %>% mutate(classe=ifelse(classe=="A", 1, 0))
binarizedValidate <- validation %>% mutate(classe=ifelse(classe=="A", 1, 0))
model1 <- train(classe~., binarizedTrain, method="rpart")
pred_validation1 <- predict(model1, newdata = binarizedValidate)
pred_submission1 <- predict(model1, newdata = testing)
pred <- predict(fit_ensemble, newdata=pred_test$classe)
pred <- predict(fit_ensemble, newdata=pred_test)
prob <- predict(fit_ensemble, newdata=pred_test, type="prob")
prob$pred <- pred
prob$classe <- validation$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", A, A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
head(prob_A$prob)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
prob$pred <- pred
prob$classe <- validation$classe
filter(prob, pred!=classe)
prob$pred <- pred
prob <- predict(fit_ensemble, newdata=pred_test, type="prob")
head(prob)
head(pred)
prob$pred <- pred
prob$classe <- validation$classe
prob$pred <- pred
prob$classe <- pred_test$classe
filter(prob, pred!=classe)
prob_A <- prob %>% mutate(prob=ifelse(pred=="A", A, A), binPred=ifelse(pred=="A", 1, 0), binClasse=ifelse(classe=="A", 1, 0))
filter(prob_A, binPred!=binClasse)
head(prob_A$prob)
head(prob_A$binClasse)
pre <- prediction(prob_A$prob, prob_A$binClasse)
class(pred)
perf <- performance(pre, measure = "tpr", x.measure = "fpr")
auc <- performance(pre, measure = "auc")
auc <- auc@y.values[[1]]
roc.data <- data.frame(fpr=unlist(perf@x.values),
tpr=unlist(perf@y.values),
model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
geom_ribbon(alpha=0.2) +
geom_line(aes(y=tpr)) +
ggtitle(paste0("ROC Curve w/ AUC=", auc))
mc_roc <- multiclass.roc(pred_ensamble, as.numeric(pred_test$classe))
plot.roc(mc_roc)
mc_roc <- multiclass.roc(pred_ensamble, as.numeric(pred_test$classe))
plot.roc(mc_roc)
summary(mc_roc)
summary(mc_roc$rocs)
summary(mc_roc$rocs[1])
plot.roc(mc_roc$rocs[1])
summary(mc_roc$rocs[1, ])
bin_roc <- roc(pred_validation1, binarizedValidate$classe)
plot.roc(bin_roc)
summary(bin_roc)
summary(mc_roc)
mc_roc$rocs[1]
bin_roc
?roc.default
?multiclass.roc
mc_roc <- multiclass.roc(pred_ensamble, as.numeric(pred_test$classe), plot=TRUE)
plot.roc(mc_roc)
plot.roc(mc_roc$rocs[1])
?plot.roc
mc_roc <- multiclass.roc(pred_ensamble, as.numeric(pred_test$classe), plot=TRUE, auc=TRUE)
mc_roc <- multiclass.roc(pred_ensamble, as.numeric(pred_test$classe), plot=TRUE)
accuracies <- list()
accuracies[1] <- 1
accuracies <- data.frame(methods=methods, preprocess=preprocess, accuracy=list())
accuracies <- data.frame(methods=methods, preprocess=preprocess, accuracy)
accuracies <- data.frame(methods=methods, preprocess=preprocess)
methods <- list("rpart", "gbm", "rf")
preprocess <- list(NULL, NULL, NULL)
accuracies <- data.frame(methods=methods, preprocess=preprocess)
accuracies <- data.frame(methods=methods, preprocess=preprocess)
accuracies <- data.frame(methods=methods)
View(accuracies)
View(accuracies)
accuracies <- data.frame(met=methods)
View(accuracies)
accuracies <- data.frame(methods, preprocess)
accuracies <- data.frame(methods, preprocess=list(NULL, NULL, NULL))
accuracies <- data.frame(preprocess)
?data.frame
accuracies <- data.frame(row.names=c("methods", "preprocess"))
View(accuracies)
accuracies$methods <- methods
?cbind
accuracies$methods <- rbind(methods)
accuracies$methods <- matrix(unlist(methods), nrow=length(methods), byrow=T)
matrix(unlist(methods), nrow=length(methods), byrow=T)
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T))
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix(unlist(preprocess), nrow=length(preprocess), byrow=T))
matrix(unlist(preprocess), nrow=length(preprocess), byrow=T)
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix())
View(accuracies)
matrix(unlist(preprocess), nrow=length(preprocess), byrow=T)
matrix(unlist(preprocess), nrow=length(preprocess), byrow=T)
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix())
accuracies$preprocess <- NULL
View(accuracies)
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix())
accuracies$preprocess <- matrix(unlist(methods), nrow=length(methods), byrow=T)
View(accuracies)
methods <- list("rpart", "gbm", "rf", "rpart", "gbm", "rf")
preprocess <- list(NULL, NULL, NULL, c("center", "scale"), c("center", "scale"), c("center", "scale"))
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix(), accuracy=matrix())
accuracies$preprocess <- matrix(unlist(preprocess), nrow=length(preprocess), byrow=T)
View(accuracies)
matrix(unlist(preprocess), nrow=length(preprocess), byrow=T)
matrix(unlist(preprocess), nrow=6, byrow=T)
preprocess <- list(NA, NA, NA, c("center", "scale"), c("center", "scale"), c("center", "scale"))
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix(), accuracy=matrix())
accuracies$preprocess <- matrix(unlist(preprocess), nrow=length(preprocess), byrow=T)
matrix(unlist(preprocess), nrow=6, byrow=T)
matrix(unlist(preprocess), nrow=6, byrow=T)
accuracies$preprocess <- ifelse(preprocess==NULL, NA, preprocess)
ifelse(preprocess==NULL, NA, preprocess)
lapply(preprocess, paste)
accuracies$preprocess <- lapply(preprocess, paste)
View(accuracies)
methods <- list("rpart", "gbm", "rf")
preprocess <- list(NULL, NULL, NULL)
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix(), accuracy=matrix())
accuracies$preprocess <- lapply(preprocess, paste)
View(accuracies)
if(is.null(preprocess))
is.null(preprocess)
is.null(unlist(preprocess))
unlist(preprocess)
unlist(preprocess)
methods <- list("rpart", "gbm", "rf", "rpart", "gbm", "rf")
preprocess <- list(NULL, NULL, NULL, c("center", "scale"), c("center", "scale"), c("center", "scale"))
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix(), accuracy=matrix())
is.null(unlist(preprocess))
methods <- list("rpart", "gbm", "rf")
preprocess <- list(NULL, NULL, NULL)
accuracies <- data.frame(methods=matrix(unlist(methods), nrow=length(methods), byrow=T), preprocess=matrix(), accuracy=matrix())
is.null(unlist(preprocess))
accuracies
library(domino)
domino.login("brunoblazinc")
domino.upload()
domino.run("Project.R")
domino.download()
for (i in 1:length(methods)) {
print(paste(i, preprocess[[i]]))
}
load("~/Documents/R programing/Practical Machine Learning/Course Project/project.RData")
for (i in 1:length(methods)) {
print(paste(i, preprocess[[i]]))
}
for (i in 1:length(methods)) {
print(preprocess[[i]])
}
domino.run("Project.R")
domino.download()
load("~/Documents/R programing/Practical Machine Learning/Course Project/project.RData")
accuracies
